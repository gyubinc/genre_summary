{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWbncAtY6iBB"
      },
      "source": [
        "# 라이브러리 다운"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S23xAJ1t6l0g"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import RobertaForSequenceClassification\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from transformers import DataCollatorWithPadding, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCT_IRGNlWCz",
        "outputId": "cda0ac23-7bec-4f52-ea3f-09e6c3c2a5e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 2.64MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.35MB/s]\n",
            "Downloading (…)lve/main/config.json: 100%|██████████| 481/481 [00:00<00:00, 192kB/s]\n",
            "Downloading pytorch_model.bin: 100%|██████████| 501M/501M [00:02<00:00, 247MB/s] \n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ynOmek56_S5"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = df['Title'].values\n",
        "        self.labels = df['Genre'].values\n",
        "        self.max_length = max_length\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.text[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZrIYQInoiTA"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('vector_data.csv',encoding = \"ISO-8859-1\")\n",
        "data = df[['Title', 'Genre']]\n",
        "\n",
        "data.to_csv('vetor_data_1.csv',index = False, encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WXzXM4E60aB"
      },
      "outputs": [],
      "source": [
        "num = len(data)\n",
        "train_df = data.iloc[:int(num*0.75), :]\n",
        "eval_df = data.iloc[int(num*0.75):, :]\n",
        "\n",
        "train_dataset = MyDataset(\n",
        "    train_df,\n",
        "    tokenizer,\n",
        "    max_length=128\n",
        ")\n",
        "\n",
        "eval_dataset = MyDataset(\n",
        "    eval_df,\n",
        "    tokenizer,\n",
        "    max_length=128\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj0H3w5-3cpw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkkXRjxI1hwn"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=5,              # total number of training epochs\n",
        "    per_device_train_batch_size=4,   # batch size per device during training\n",
        "    per_device_eval_batch_size=4,   # batch size for evaluation\n",
        "    warmup_steps=1000,               # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=200,               # How often to print logs\n",
        "    do_train=True,                   # Perform training\n",
        "    do_eval=True,                    # Perform evaluation\n",
        "    evaluation_strategy=\"epoch\",     # evalute after eachh epoch\n",
        "    run_name=\"ProBert-BFD-MS\",       # experiment name\n",
        "    seed=3      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vdIIBi6xLFD"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# def compute_metrics(eval_pred):\n",
        "#     logits, labels = eval_pred\n",
        "#     predictions = np.argmax(logits, axis=-1)\n",
        "#     return {'accuracy': accuracy_score(labels, predictions)}\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=eval_dataset,\n",
        "#     compute_metrics=compute_metrics,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgyhTQjqxPgY"
      },
      "outputs": [],
      "source": [
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujQk48Jo9kme"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class MyTrainer(Trainer):\n",
        "    def get_train_dataloader(self):\n",
        "        if self.train_dataset is None:\n",
        "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
        "        data_loader = DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.args.train_batch_size,\n",
        "            drop_last=self.args.dataloader_drop_last,\n",
        "            num_workers=self.args.dataloader_num_workers,\n",
        "        )\n",
        "        return data_loader\n",
        "\n",
        "    def get_eval_dataloader(self, eval_dataset=None):\n",
        "        if eval_dataset is None and self.eval_dataset is None:\n",
        "            raise ValueError(\"Trainer: evaluation requires an eval_dataset.\")\n",
        "        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
        "        data_loader = DataLoader(\n",
        "            eval_dataset,\n",
        "            batch_size=self.args.eval_batch_size,\n",
        "            drop_last=self.args.dataloader_drop_last,\n",
        "            num_workers=self.args.dataloader_num_workers,\n",
        "        )\n",
        "        return data_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "3fkTON-29mOS",
        "outputId": "f2d77109-8eda-4cf1-8a07-aa2cc8ec5842"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-adc4bc8a5ffe>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         )\n\u001b[0;32m-> 1645\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrng_to_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2794\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2795\u001b[0m         \u001b[0;34m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2796\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2797\u001b[0m         \u001b[0mn_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-125-f86abd324223>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         encoding = self.tokenizer.encode_plus(\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2738\u001b[0m         )\n\u001b[1;32m   2739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2740\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   2741\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m             )\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    633\u001b[0m                     )\n\u001b[1;32m    634\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    636\u001b[0m                         \u001b[0;34mf\"Input {text} is not valid. Should be a string, a list/tuple of strings or a list/tuple of\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                         \u001b[0;34m\" integers.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input ['Doug the Pug 2016 Wall Calendar'\n 'Moleskine 2016 Weekly Notebook, 12M, Large, Black, Soft Cover (5 x 8.25)'\n '365 Cats Color Page-A-Day Calendar 2016'\n 'Sierra Club Engagement Calendar 2016'] is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
          ]
        }
      ],
      "source": [
        "trainer = MyTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw4q2c39DR-K"
      },
      "source": [
        "# 재시도"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "J1wIVBQ5EJk-",
        "outputId": "ae56ad7d-740c-45dd-cde1-447c5915f070"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-1ec7eac5-cbbb-4631-b1b4-62e29c20591b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Doug the Pug 2016 Wall Calendar</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Moleskine 2016 Weekly Notebook, 12M, Large, Bl...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>365 Cats Color Page-A-Day Calendar 2016</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sierra Club Engagement Calendar 2016</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Sierra Club Wilderness Calendar 2016</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ec7eac5-cbbb-4631-b1b4-62e29c20591b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-428cf167-dc27-4097-9f0b-064a3748b640\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-428cf167-dc27-4097-9f0b-064a3748b640')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-428cf167-dc27-4097-9f0b-064a3748b640 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ec7eac5-cbbb-4631-b1b4-62e29c20591b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ec7eac5-cbbb-4631-b1b4-62e29c20591b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Unnamed: 0                                              Title  Genre\n",
              "0           0                    Doug the Pug 2016 Wall Calendar      3\n",
              "1           1  Moleskine 2016 Weekly Notebook, 12M, Large, Bl...      3\n",
              "2           2            365 Cats Color Page-A-Day Calendar 2016      3\n",
              "3           3               Sierra Club Engagement Calendar 2016      3\n",
              "4           4               Sierra Club Wilderness Calendar 2016      3"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA2USxExlGVo"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509,
          "referenced_widgets": [
            "0dfc9118ee7d42fa92fda279345d10dd",
            "22381a54d4854bf9b91359a7a9350376",
            "eaf55fce655d4994a5cd9ff1487eaa56",
            "c8f876bb3e8a4450b7e29cf00156ea37",
            "8e17a5a48f53479ca136c6c138475c3b",
            "1f592f8297cb492d987487fed60b7bac",
            "febf78deccd44831ac99ae03bb101b28",
            "a99cfadba4584518b70ede37056ab334",
            "6fd7f606fd5042518f2142b3f469d1f3",
            "70e0015724664798b85a9160c134d3c8",
            "b56860f34bc44924a64a1867f01fa074",
            "a86e1d0dd148442da26f04b02a69956c",
            "6e3e6be2f7d34a04a777ee11f0193ae2",
            "082e886bae1d4e3c9465f20be3d4c447",
            "44216e22badc4bb2bff956981fb96822",
            "2bbcaa400d30438886f13c9a0bb0a952",
            "72db8ce1a8e145d4b304579700e3a5af",
            "172c2cbc98394b6a8cb8c95422c135c3",
            "b32192206341455bbebaf55c5d760d41",
            "a392e021f32b49498aeca03c7086ab01",
            "f0e5d8adfa1a400a81068b1b6b0592f7",
            "c715271327374383b715b8bae194bf73"
          ]
        },
        "id": "NQfV84foDTIT",
        "outputId": "69bfe985-b3ab-4007-d8e5-0527a626ac80"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dfc9118ee7d42fa92fda279345d10dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/155678 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a86e1d0dd148442da26f04b02a69956c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/51893 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b337309dacda>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     77\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         )\n\u001b[0;32m-> 1645\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2758\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2759\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b337309dacda>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(model, inputs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Override the compute_loss method of the Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'labels'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv('/content/vetor_data_1.csv', encoding=\"ISO-8859-1\")\n",
        "\n",
        "# Genre 데이터의 범주를 정수 인덱스로 변환\n",
        "label_encoder = LabelEncoder()\n",
        "df['Genre'] = label_encoder.fit_transform(df['Genre'])\n",
        "\n",
        "# Convert the DataFrame into a Hugging Face Dataset\n",
        "data = Dataset.from_pandas(df)\n",
        "\n",
        "# Tokenizer initialization\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "# Tokenize function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"Title\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Split dataset into train and test\n",
        "raw_datasets = data.train_test_split(test_size=0.25)\n",
        "\n",
        "# Map the tokenization function to the title text (it will also remove the column 'Title' and replace it with the new ones)\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True, remove_columns=[\"Title\"])\n",
        "\n",
        "# Model initialization\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=32)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    \"test_trainer\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "# Compute metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='macro')\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# Override the compute_loss method of the Trainer\n",
        "def compute_loss(model, inputs):\n",
        "    labels = inputs.pop(\"labels\")\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    loss = loss_fn(logits, labels)\n",
        "    return loss\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")\n",
        "trainer.compute_loss = compute_loss\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "all input arrays must have the same shape",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 63\u001b[0m\n\u001b[1;32m     55\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     56\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     57\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m     58\u001b[0m     train_dataset\u001b[39m=\u001b[39mtrain_dataset,\n\u001b[1;32m     59\u001b[0m     eval_dataset\u001b[39m=\u001b[39meval_dataset\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[39m# 학습 시작\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     65\u001b[0m \u001b[39m# 임의의 데이터에 대한 예측\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_genre\u001b[39m(title):\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:1664\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1661\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1662\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1663\u001b[0m )\n\u001b[0;32m-> 1664\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1665\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1666\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1667\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1668\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1669\u001b[0m )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:1909\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1906\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1908\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 1909\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1910\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1911\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer_utils.py:704\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, features: List[\u001b[39mdict\u001b[39m]):\n\u001b[1;32m    703\u001b[0m     features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remove_columns(feature) \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features]\n\u001b[0;32m--> 704\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_collator(features)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/data/data_collator.py:70\u001b[0m, in \u001b[0;36mdefault_data_collator\u001b[0;34m(features, return_tensors)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m# In this function we'll make the assumption that all `features` in the batch\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m# have the same attributes.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m# So we will look at the first element as a proxy for what attributes exist\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m# on the whole batch.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m torch_default_data_collator(features)\n\u001b[1;32m     71\u001b[0m \u001b[39melif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m tf_default_data_collator(features)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/data/data_collator.py:134\u001b[0m, in \u001b[0;36mtorch_default_data_collator\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m    132\u001b[0m     batch[k] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([f[k] \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m features])\n\u001b[1;32m    133\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m--> 134\u001b[0m     batch[k] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39;49mstack([f[k] \u001b[39mfor\u001b[39;49;00m f \u001b[39min\u001b[39;49;00m features]))\n\u001b[1;32m    135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     batch[k] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([f[k] \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m features])\n",
            "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/core/shape_base.py:426\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    424\u001b[0m shapes \u001b[39m=\u001b[39m {arr\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays}\n\u001b[1;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shapes) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 426\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mall input arrays must have the same shape\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    428\u001b[0m result_ndim \u001b[39m=\u001b[39m arrays[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mndim \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    429\u001b[0m axis \u001b[39m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
            "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "\n",
        "# csv 파일 읽기\n",
        "df = pd.read_csv('vetor_data_1.csv', encoding=\"ISO-8859-1\")\n",
        "\n",
        "# Title을 tokenizing\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "df['Title'] = df['Title'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=512))\n",
        "\n",
        "\n",
        "# 32개의 Genre를 binary encoding\n",
        "mlb = MultiLabelBinarizer()\n",
        "df['Genre'] = df['Genre'].apply(lambda x: mlb.fit_transform([x]))\n",
        "\n",
        "\n",
        "# 데이터셋을 train과 eval로 나누기\n",
        "train_df, eval_df = train_test_split(df, test_size=0.2)\n",
        "\n",
        "# PyTorch의 Dataset을 만들기 위한 클래스 정의\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.encodings = df['Title'].to_list()\n",
        "        self.labels = df['Genre'].to_list()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {'input_ids': self.encodings[idx], 'labels': self.labels[idx]}\n",
        "        return item\n",
        "\n",
        "\n",
        "# Dataset 만들기\n",
        "train_dataset = Dataset(train_df)\n",
        "eval_dataset = Dataset(eval_df)\n",
        "\n",
        "# 모델 초기화\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=32)\n",
        "\n",
        "# TrainingArguments와 Trainer 초기화\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset\n",
        ")\n",
        "\n",
        "# 학습 시작\n",
        "trainer.train()\n",
        "\n",
        "# 임의의 데이터에 대한 예측\n",
        "def predict_genre(title):\n",
        "    inputs = tokenizer(title, return_tensors='pt')\n",
        "    logits = model(**inputs).logits\n",
        "    result = torch.sigmoid(logits)\n",
        "    return mlb.inverse_transform(result.detach().numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# retry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('vetor_data_1.csv', encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris # 샘플 데이터 로딩\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load sample\n",
        "\n",
        "data = df['Title']\n",
        "target = df['Genre']\n",
        "\n",
        "# train_test_split\n",
        "x_train_1, x_valid_1, y_train_1, y_valid_1 = train_test_split(data, target, test_size=0.1, shuffle=True, stratify=target, random_state=34)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17001' max='17514' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17001/17514 1:28:18 < 02:39, 3.21 it/s, Epoch 2.91/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.690900</td>\n",
              "      <td>1.840073</td>\n",
              "      <td>0.525870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.660000</td>\n",
              "      <td>1.496850</td>\n",
              "      <td>0.595867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.449900</td>\n",
              "      <td>1.377236</td>\n",
              "      <td>0.625542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.388000</td>\n",
              "      <td>1.303609</td>\n",
              "      <td>0.642066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.334100</td>\n",
              "      <td>1.260815</td>\n",
              "      <td>0.653676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.260600</td>\n",
              "      <td>1.239829</td>\n",
              "      <td>0.653531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.260500</td>\n",
              "      <td>1.223326</td>\n",
              "      <td>0.658638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.232300</td>\n",
              "      <td>1.191354</td>\n",
              "      <td>0.666827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.213200</td>\n",
              "      <td>1.176619</td>\n",
              "      <td>0.671741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.190500</td>\n",
              "      <td>1.158251</td>\n",
              "      <td>0.676029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.143000</td>\n",
              "      <td>1.138054</td>\n",
              "      <td>0.683110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.111500</td>\n",
              "      <td>1.136927</td>\n",
              "      <td>0.682580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.951800</td>\n",
              "      <td>1.133301</td>\n",
              "      <td>0.685856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.950400</td>\n",
              "      <td>1.133439</td>\n",
              "      <td>0.687012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.938200</td>\n",
              "      <td>1.125070</td>\n",
              "      <td>0.688939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.928600</td>\n",
              "      <td>1.119393</td>\n",
              "      <td>0.690625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.916600</td>\n",
              "      <td>1.110724</td>\n",
              "      <td>0.691011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.935400</td>\n",
              "      <td>1.097714</td>\n",
              "      <td>0.695539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.945400</td>\n",
              "      <td>1.089882</td>\n",
              "      <td>0.697081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.938900</td>\n",
              "      <td>1.085131</td>\n",
              "      <td>0.695732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.940600</td>\n",
              "      <td>1.077141</td>\n",
              "      <td>0.697466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.922200</td>\n",
              "      <td>1.075076</td>\n",
              "      <td>0.695250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.890000</td>\n",
              "      <td>1.070130</td>\n",
              "      <td>0.700501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.774900</td>\n",
              "      <td>1.083888</td>\n",
              "      <td>0.697081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.716400</td>\n",
              "      <td>1.099604</td>\n",
              "      <td>0.696984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.708600</td>\n",
              "      <td>1.101436</td>\n",
              "      <td>0.697996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.722300</td>\n",
              "      <td>1.101481</td>\n",
              "      <td>0.698430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.691200</td>\n",
              "      <td>1.103563</td>\n",
              "      <td>0.700886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.706800</td>\n",
              "      <td>1.100704</td>\n",
              "      <td>0.700453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.697000</td>\n",
              "      <td>1.095009</td>\n",
              "      <td>0.699297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.688900</td>\n",
              "      <td>1.096454</td>\n",
              "      <td>0.700116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.690400</td>\n",
              "      <td>1.094865</td>\n",
              "      <td>0.702765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.683200</td>\n",
              "      <td>1.092124</td>\n",
              "      <td>0.701850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.701800</td>\n",
              "      <td>1.091949</td>\n",
              "      <td>0.702139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "[enforce fail at inline_container.cc:337] . unexpected pos 428645824 vs 428645712",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m     _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:668\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    667\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n\u001b[0;32m--> 668\u001b[0m zip_file\u001b[39m.\u001b[39;49mwrite_record(name, storage\u001b[39m.\u001b[39;49mdata_ptr(), num_bytes)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:471] . PytorchStreamWriter failed writing file data/98: file write failed",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 74\u001b[0m\n\u001b[1;32m     65\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     66\u001b[0m     model\u001b[39m=\u001b[39mmodel,                         \u001b[39m# 학습시킬 모델\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,                  \u001b[39m# 학습 인자\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics      \u001b[39m# 평가 메트릭 계산 함수\u001b[39;00m\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[39m# 모델 학습\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:1664\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1661\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1662\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1663\u001b[0m )\n\u001b[0;32m-> 1664\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1665\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1666\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1667\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1668\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1669\u001b[0m )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:2019\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m epoch \u001b[39m+\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m steps_skipped) \u001b[39m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2017\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 2019\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   2020\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2021\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_substep_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:2308\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2305\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mstep(metrics[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mmetric_for_best_model])\n\u001b[1;32m   2307\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n\u001b[0;32m-> 2308\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_checkpoint(model, trial, metrics\u001b[39m=\u001b[39;49mmetrics)\n\u001b[1;32m   2309\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_save(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:2365\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2363\u001b[0m run_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_output_dir(trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m   2364\u001b[0m output_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 2365\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_model(output_dir, _internal_call\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   2366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed:\n\u001b[1;32m   2367\u001b[0m     \u001b[39m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001b[39;00m\n\u001b[1;32m   2368\u001b[0m     \u001b[39m# config `stage3_gather_16bit_weights_on_model_save` is True\u001b[39;00m\n\u001b[1;32m   2369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed\u001b[39m.\u001b[39msave_checkpoint(output_dir)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:2866\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2863\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed\u001b[39m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   2865\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n\u001b[0;32m-> 2866\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save(output_dir)\n\u001b[1;32m   2868\u001b[0m \u001b[39m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2869\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _internal_call:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:2922\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2920\u001b[0m             torch\u001b[39m.\u001b[39msave(state_dict, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   2921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2922\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49msave_pretrained(\n\u001b[1;32m   2923\u001b[0m         output_dir, state_dict\u001b[39m=\u001b[39;49mstate_dict, safe_serialization\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49msave_safetensors\n\u001b[1;32m   2924\u001b[0m     )\n\u001b[1;32m   2926\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2927\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39msave_pretrained(output_dir)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:1825\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, **kwargs)\u001b[0m\n\u001b[1;32m   1823\u001b[0m         safe_save_file(shard, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_directory, shard_file), metadata\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m   1824\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1825\u001b[0m         save_function(shard, os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(save_directory, shard_file))\n\u001b[1;32m   1827\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1828\u001b[0m     path_to_weights \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_directory, _add_variant(WEIGHTS_NAME, variant))\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:442\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m--> 442\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m     \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m opened_file:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:291\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_like\u001b[39m.\u001b[39;49mwrite_end_of_file()\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:337] . unexpected pos 428645824 vs 428645712"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
            "    self._process(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n",
            "    self._hm.handle(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 146, in handle_request\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 729, in handle_request_pause\n",
            "    self._system_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 190, in finish\n",
            "    logger.info(\"Stopping system monitor\")\n",
            "Message: 'Stopping system monitor'\n",
            "Arguments: ()\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 166, in _start\n",
            "    logger.debug(\"Finished system metrics aggregation loop\")\n",
            "Message: 'Finished system metrics aggregation loop'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
            "    self._process(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n",
            "    self._hm.handle(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 146, in handle_request\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 729, in handle_request_pause\n",
            "    self._system_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 193, in finish\n",
            "    asset.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/cpu.py\", line 163, in finish\n",
            "    self.metrics_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n",
            "    logger.info(f\"Joined {thread_name} monitor\")\n",
            "Message: 'Joined cpu monitor'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 170, in _start\n",
            "    logger.debug(\"Publishing last batch of metrics\")\n",
            "Message: 'Publishing last batch of metrics'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
            "    self._process(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n",
            "    self._hm.handle(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 146, in handle_request\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 729, in handle_request_pause\n",
            "    self._system_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 193, in finish\n",
            "    asset.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/disk.py\", line 77, in finish\n",
            "    self.metrics_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n",
            "    logger.info(f\"Joined {thread_name} monitor\")\n",
            "Message: 'Joined disk monitor'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
            "    self._process(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n",
            "    self._hm.handle(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 146, in handle_request\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 729, in handle_request_pause\n",
            "    self._system_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 193, in finish\n",
            "    asset.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/gpu.py\", line 388, in finish\n",
            "    self.metrics_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n",
            "    logger.info(f\"Joined {thread_name} monitor\")\n",
            "Message: 'Joined gpu monitor'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
            "    self._process(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n",
            "    self._hm.handle(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 146, in handle_request\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 729, in handle_request_pause\n",
            "    self._system_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 193, in finish\n",
            "    asset.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/memory.py\", line 152, in finish\n",
            "    self.metrics_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n",
            "    logger.info(f\"Joined {thread_name} monitor\")\n",
            "Message: 'Joined memory monitor'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
            "    self._process(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n",
            "    self._hm.handle(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 146, in handle_request\n",
            "    handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 729, in handle_request_pause\n",
            "    self._system_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 193, in finish\n",
            "    asset.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/network.py\", line 96, in finish\n",
            "    self.metrics_monitor.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n",
            "    logger.info(f\"Joined {thread_name} monitor\")\n",
            "Message: 'Joined network monitor'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1526, in finish\n",
            "    logger.info(\"shutting down sender\")\n",
            "Message: 'shutting down sender'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n",
            "    self._hm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 854, in finish\n",
            "    logger.info(\"shutting down handler\")\n",
            "Message: 'shutting down handler'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1531, in finish\n",
            "    self._dir_watcher.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 359, in finish\n",
            "    logger.info(\"shutting down directory watcher\")\n",
            "Message: 'shutting down directory watcher'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1531, in finish\n",
            "    self._dir_watcher.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 373, in finish\n",
            "    self._file_observer.dispatch_events(\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 368, in dispatch_events\n",
            "    handler.dispatch(event)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/events.py\", line 454, in dispatch\n",
            "    _method_map[event_type](event)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 289, in _on_file_modified\n",
            "    logger.info(f\"file/dir modified: { event.src_path}\")\n",
            "Message: 'file/dir modified: /opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/output.log'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1531, in finish\n",
            "    self._dir_watcher.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 389, in finish\n",
            "    logger.info(\"scan: %s\", self._dir)\n",
            "Message: 'scan: %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files',)\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1531, in finish\n",
            "    self._dir_watcher.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 403, in finish\n",
            "    logger.info(\"scan save: %s %s\", file_path, save_name)\n",
            "Message: 'scan save: %s %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/wandb-summary.json', 'wandb-summary.json')\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1531, in finish\n",
            "    self._dir_watcher.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 403, in finish\n",
            "    logger.info(\"scan save: %s %s\", file_path, save_name)\n",
            "Message: 'scan save: %s %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/output.log', 'output.log')\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1531, in finish\n",
            "    self._dir_watcher.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 403, in finish\n",
            "    logger.info(\"scan save: %s %s\", file_path, save_name)\n",
            "Message: 'scan save: %s %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/conda-environment.yaml', 'conda-environment.yaml')\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1531, in finish\n",
            "    self._dir_watcher.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 403, in finish\n",
            "    logger.info(\"scan save: %s %s\", file_path, save_name)\n",
            "Message: 'scan save: %s %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/wandb-metadata.json', 'wandb-metadata.json')\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1531, in finish\n",
            "    self._dir_watcher.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 403, in finish\n",
            "    logger.info(\"scan save: %s %s\", file_path, save_name)\n",
            "Message: 'scan save: %s %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/config.yaml', 'config.yaml')\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1531, in finish\n",
            "    self._dir_watcher.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 403, in finish\n",
            "    logger.info(\"scan save: %s %s\", file_path, save_name)\n",
            "Message: 'scan save: %s %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/requirements.txt', 'requirements.txt')\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1534, in finish\n",
            "    self._pusher.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/file_pusher.py\", line 159, in finish\n",
            "    logger.info(\"shutting down file pusher\")\n",
            "Message: 'shutting down file pusher'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
            "    self._finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
            "    self._sm.finish()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1535, in finish\n",
            "    self._pusher.join()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/file_pusher.py\", line 164, in join\n",
            "    logger.info(\"waiting for file pusher\")\n",
            "Message: 'waiting for file pusher'\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/concurrent/futures/thread.py\", line 80, in _worker\n",
            "    work_item.run()\n",
            "  File \"/opt/conda/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/step_upload.py\", line 288, in run_and_notify\n",
            "    self._do_upload_sync(event)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
            "    job.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 57, in run\n",
            "    self.push()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 133, in push\n",
            "    logger.info(\"Uploaded file %s\", self.save_path)\n",
            "Message: 'Uploaded file %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/output.log',)\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/concurrent/futures/thread.py\", line 80, in _worker\n",
            "    work_item.run()\n",
            "  File \"/opt/conda/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/step_upload.py\", line 288, in run_and_notify\n",
            "    self._do_upload_sync(event)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
            "    job.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 57, in run\n",
            "    self.push()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 133, in push\n",
            "    logger.info(\"Uploaded file %s\", self.save_path)\n",
            "Message: 'Uploaded file %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/wandb-summary.json',)\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/concurrent/futures/thread.py\", line 80, in _worker\n",
            "    work_item.run()\n",
            "  File \"/opt/conda/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/step_upload.py\", line 288, in run_and_notify\n",
            "    self._do_upload_sync(event)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
            "    job.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 57, in run\n",
            "    self.push()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 133, in push\n",
            "    logger.info(\"Uploaded file %s\", self.save_path)\n",
            "Message: 'Uploaded file %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/requirements.txt',)\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/concurrent/futures/thread.py\", line 80, in _worker\n",
            "    work_item.run()\n",
            "  File \"/opt/conda/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/step_upload.py\", line 288, in run_and_notify\n",
            "    self._do_upload_sync(event)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
            "    job.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 57, in run\n",
            "    self.push()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 133, in push\n",
            "    logger.info(\"Uploaded file %s\", self.save_path)\n",
            "Message: 'Uploaded file %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/conda-environment.yaml',)\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/concurrent/futures/thread.py\", line 80, in _worker\n",
            "    work_item.run()\n",
            "  File \"/opt/conda/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/step_upload.py\", line 288, in run_and_notify\n",
            "    self._do_upload_sync(event)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
            "    job.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 57, in run\n",
            "    self.push()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 133, in push\n",
            "    logger.info(\"Uploaded file %s\", self.save_path)\n",
            "Message: 'Uploaded file %s'\n",
            "Arguments: ('/opt/ml/genre_summary/classification/wandb/run-20230720_024649-i4hzmytt/files/config.yaml',)\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    self.flush()\n",
            "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
            "    self.stream.flush()\n",
            "OSError: [Errno 28] No space left on device\n",
            "Call stack:\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/service/streams.py\", line 49, in run\n",
            "    self._target(**self._kwargs)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 174, in wandb_internal\n",
            "    logger.error(f\"Thread {thread.name}:\", exc_info=exc_info)\n",
            "Message: 'Thread WriterThread:'\n",
            "Arguments: ()\n",
            "Thread WriterThread:\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
            "    self._run()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
            "    self._process(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 380, in _process\n",
            "    self._wm.write(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/writer.py\", line 154, in write\n",
            "    write_handler(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/writer.py\", line 135, in _write\n",
            "    self._write_record(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/writer.py\", line 109, in _write_record\n",
            "    ret = self._ds.write(record)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/datastore.py\", line 293, in write\n",
            "    ret = self._write_data(s)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/datastore.py\", line 249, in _write_data\n",
            "    self._write_record(s)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/datastore.py\", line 228, in _write_record\n",
            "    self._fp.write(s)\n",
            "OSError: [Errno 28] No space left on device\n",
            "wandb: ERROR Internal wandb error: file data was not synced\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# 정확도를 계산하는 함수\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)}\n",
        "\n",
        "# 데이터 로드 및 토큰화\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# 만약 x_train과 x_valid가 pandas Series 객체라면, 이를 list로 변환\n",
        "x_train = x_train_1.tolist()\n",
        "x_valid = x_valid_1.tolist()\n",
        "\n",
        "# y_train과 y_valid가 텍스트 라벨이라면, 이를 정수형 라벨로 변환\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_valid = le.transform(y_valid)\n",
        "\n",
        "train_encodings = tokenizer(x_train, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(x_valid, truncation=True, padding=True)\n",
        "\n",
        "# 데이터셋 생성\n",
        "train_dataset = CustomDataset(train_encodings, y_train)\n",
        "valid_dataset = CustomDataset(valid_encodings, y_valid)\n",
        "\n",
        "# 모델 생성\n",
        "num_labels = len(set(y_train))  # 클래스 수를 정의합니다.\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "\n",
        "# 학습 및 검증 인자 정의\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # 출력 결과를 저장할 경로\n",
        "    num_train_epochs=3,              # 훈련 에포크 수\n",
        "    per_device_train_batch_size=32,  # 훈련 배치 크기\n",
        "    per_device_eval_batch_size=32,   # 검증 배치 크기\n",
        "    warmup_steps=500,                # 워밍업 스텝 수\n",
        "    weight_decay=0.01,         \n",
        "    learning_rate = 3e-05,# 가중치 감쇠 비율\n",
        "    logging_dir='./logs',            # 로그를 저장할 경로\n",
        "    logging_steps=500,                # 로깅할 스텝 크기\n",
        "    evaluation_strategy='steps',     # 스텝마다 evaluation을 수행합니다.\n",
        "    eval_steps=500,                  # 500스텝마다 evaluation을 수행합니다.\n",
        ")\n",
        "\n",
        "# Trainer 생성 및 학습\n",
        "trainer = Trainer(\n",
        "    model=model,                         # 학습시킬 모델\n",
        "    args=training_args,                  # 학습 인자\n",
        "    train_dataset=train_dataset,         # 훈련 데이터셋\n",
        "    eval_dataset=valid_dataset,          # 검증 데이터셋\n",
        "    compute_metrics=compute_metrics      # 평가 메트릭 계산 함수\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 저장\n",
        "trainer.save_model(\"./model/save_last\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ROBERTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "182399           Children's Books\n",
            "170154         Teen & Young Adult\n",
            "4138      Comics & Graphic Novels\n",
            "47472      Crafts, Hobbies & Home\n",
            "185004           Children's Books\n",
            "                   ...           \n",
            "183203           Children's Books\n",
            "46799      Crafts, Hobbies & Home\n",
            "203282                     Travel\n",
            "157723    Religion & Spirituality\n",
            "48450      Crafts, Hobbies & Home\n",
            "Name: Genre, Length: 186813, dtype: object\n",
            "[ 4 29  6 ... 31 23  9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8757' max='8757' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8757/8757 1:35:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.684300</td>\n",
              "      <td>1.647982</td>\n",
              "      <td>0.557568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.518800</td>\n",
              "      <td>1.431175</td>\n",
              "      <td>0.606031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.403600</td>\n",
              "      <td>1.356266</td>\n",
              "      <td>0.621351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.354000</td>\n",
              "      <td>1.283303</td>\n",
              "      <td>0.642644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.417700</td>\n",
              "      <td>1.245308</td>\n",
              "      <td>0.655217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.049500</td>\n",
              "      <td>1.216004</td>\n",
              "      <td>0.658300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.120600</td>\n",
              "      <td>1.212286</td>\n",
              "      <td>0.663070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.128000</td>\n",
              "      <td>1.185626</td>\n",
              "      <td>0.666827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.040600</td>\n",
              "      <td>1.161766</td>\n",
              "      <td>0.674583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.029700</td>\n",
              "      <td>1.148180</td>\n",
              "      <td>0.674150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.976300</td>\n",
              "      <td>1.125912</td>\n",
              "      <td>0.682628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.901600</td>\n",
              "      <td>1.115619</td>\n",
              "      <td>0.685904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.929900</td>\n",
              "      <td>1.116471</td>\n",
              "      <td>0.685712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.853500</td>\n",
              "      <td>1.117026</td>\n",
              "      <td>0.689614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.748100</td>\n",
              "      <td>1.102750</td>\n",
              "      <td>0.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.821100</td>\n",
              "      <td>1.097026</td>\n",
              "      <td>0.693323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.852800</td>\n",
              "      <td>1.094455</td>\n",
              "      <td>0.693757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8757, training_loss=1.1734862831257733, metrics={'train_runtime': 5760.5032, 'train_samples_per_second': 97.29, 'train_steps_per_second': 1.52, 'total_flos': 4.8973751289936e+16, 'train_loss': 1.1734862831257733, 'epoch': 3.0})"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# 정확도를 계산하는 함수\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)}\n",
        "\n",
        "# 데이터 로드 및 토큰화\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
        "\n",
        "# 만약 x_train과 x_valid가 pandas Series 객체라면, 이를 list로 변환\n",
        "x_train = x_train_1.tolist()\n",
        "x_valid = x_valid_1.tolist()\n",
        "\n",
        "print(y_train_1)\n",
        "\n",
        "# y_train과 y_valid가 텍스트 라벨이라면, 이를 정수형 라벨로 변환\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train_1)\n",
        "y_valid = le.transform(y_valid_1)\n",
        "\n",
        "print(y_train)\n",
        "\n",
        "import pickle\n",
        "\n",
        "# LabelEncoder 객체를 저장합니다.\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "# 나중에 LabelEncoder 객체를 로드합니다.\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    loaded_le = pickle.load(f)\n",
        "\n",
        "\n",
        "train_encodings = tokenizer(x_train, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(x_valid, truncation=True, padding=True)\n",
        "\n",
        "# 데이터셋 생성\n",
        "train_dataset = CustomDataset(train_encodings, y_train)\n",
        "valid_dataset = CustomDataset(valid_encodings, y_valid)\n",
        "\n",
        "# 모델 생성\n",
        "num_labels = len(set(y_train))  # 클래스 수를 정의합니다.\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
        "\n",
        "# 학습 및 검증 인자 정의\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # 출력 결과를 저장할 경로\n",
        "    num_train_epochs=3,              # 훈련 에포크 수\n",
        "    per_device_train_batch_size=64,  # 훈련 배치 크기\n",
        "    per_device_eval_batch_size=64,\n",
        "    learning_rate = 5e-05,# 검증 배치 크기\n",
        "    warmup_steps=500,                # 워밍업 스텝 수\n",
        "    weight_decay=0.01,               # 가중치 감쇠 비율\n",
        "    logging_dir='./logs',            # 로그를 저장할 경로\n",
        "    logging_steps=10,                # 로깅할 스텝 크기\n",
        "    evaluation_strategy='steps',     # 스텝마다 evaluation을 수행합니다.\n",
        "    eval_steps=500,                  # 500스텝마다 evaluation을 수행합니다.\n",
        ")\n",
        "\n",
        "# Trainer 생성 및 학습\n",
        "trainer = Trainer(\n",
        "    model=model,                         # 학습시킬 모델\n",
        "    args=training_args,                  # 학습 인자\n",
        "    train_dataset=train_dataset,         # 훈련 데이터셋\n",
        "    eval_dataset=valid_dataset,          # 검증 데이터셋\n",
        "    compute_metrics=compute_metrics      # 평가 메트릭 계산 함수\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Roberta-large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "182399           Children's Books\n",
            "170154         Teen & Young Adult\n",
            "4138      Comics & Graphic Novels\n",
            "47472      Crafts, Hobbies & Home\n",
            "185004           Children's Books\n",
            "                   ...           \n",
            "183203           Children's Books\n",
            "46799      Crafts, Hobbies & Home\n",
            "203282                     Travel\n",
            "157723    Religion & Spirituality\n",
            "48450      Crafts, Hobbies & Home\n",
            "Name: Genre, Length: 186813, dtype: object\n",
            "[ 4 29  6 ... 31 23  9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myeppi315\u001b[0m (\u001b[33mgyubin5009\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.15.5 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/opt/ml/genre_summary/classification/wandb/run-20230718_205949-2bbcgk0y</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gyubin5009/huggingface/runs/2bbcgk0y' target=\"_blank\">hardy-sponge-10</a></strong> to <a href='https://wandb.ai/gyubin5009/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gyubin5009/huggingface' target=\"_blank\">https://wandb.ai/gyubin5009/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gyubin5009/huggingface/runs/2bbcgk0y' target=\"_blank\">https://wandb.ai/gyubin5009/huggingface/runs/2bbcgk0y</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34028' max='70056' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34028/70056 4:08:14 < 4:22:50, 2.28 it/s, Epoch 1.46/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.509800</td>\n",
              "      <td>1.670472</td>\n",
              "      <td>0.553377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.650300</td>\n",
              "      <td>1.504154</td>\n",
              "      <td>0.594325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.521500</td>\n",
              "      <td>1.390908</td>\n",
              "      <td>0.621929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.453100</td>\n",
              "      <td>1.362344</td>\n",
              "      <td>0.624819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.398100</td>\n",
              "      <td>1.362916</td>\n",
              "      <td>0.626072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.364200</td>\n",
              "      <td>1.307148</td>\n",
              "      <td>0.637971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.378900</td>\n",
              "      <td>1.282162</td>\n",
              "      <td>0.641969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.332000</td>\n",
              "      <td>1.270696</td>\n",
              "      <td>0.649822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>1.320400</td>\n",
              "      <td>1.250407</td>\n",
              "      <td>0.653917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.310000</td>\n",
              "      <td>1.235423</td>\n",
              "      <td>0.655554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>1.235900</td>\n",
              "      <td>1.237964</td>\n",
              "      <td>0.656470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.267600</td>\n",
              "      <td>1.220746</td>\n",
              "      <td>0.661576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>1.251300</td>\n",
              "      <td>1.212441</td>\n",
              "      <td>0.661191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.240300</td>\n",
              "      <td>1.197873</td>\n",
              "      <td>0.664419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>1.233100</td>\n",
              "      <td>1.200783</td>\n",
              "      <td>0.664419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>1.230500</td>\n",
              "      <td>1.173802</td>\n",
              "      <td>0.672608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>1.228600</td>\n",
              "      <td>1.182299</td>\n",
              "      <td>0.670055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>1.202400</td>\n",
              "      <td>1.142388</td>\n",
              "      <td>0.680316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>1.185900</td>\n",
              "      <td>1.150589</td>\n",
              "      <td>0.680364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>1.196100</td>\n",
              "      <td>1.149157</td>\n",
              "      <td>0.678485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>1.165400</td>\n",
              "      <td>1.145514</td>\n",
              "      <td>0.679015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>1.128700</td>\n",
              "      <td>1.140298</td>\n",
              "      <td>0.681280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>1.185400</td>\n",
              "      <td>1.135027</td>\n",
              "      <td>0.682339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>1.073000</td>\n",
              "      <td>1.147511</td>\n",
              "      <td>0.684218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>1.003900</td>\n",
              "      <td>1.148527</td>\n",
              "      <td>0.684459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>1.001000</td>\n",
              "      <td>1.117196</td>\n",
              "      <td>0.687831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>1.012800</td>\n",
              "      <td>1.145255</td>\n",
              "      <td>0.687639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>1.010700</td>\n",
              "      <td>1.140422</td>\n",
              "      <td>0.684411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>0.996300</td>\n",
              "      <td>1.121761</td>\n",
              "      <td>0.690336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>0.964500</td>\n",
              "      <td>1.131048</td>\n",
              "      <td>0.689758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31000</td>\n",
              "      <td>0.971300</td>\n",
              "      <td>1.121356</td>\n",
              "      <td>0.690433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>0.989100</td>\n",
              "      <td>1.126158</td>\n",
              "      <td>0.691444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33000</td>\n",
              "      <td>0.947900</td>\n",
              "      <td>1.109962</td>\n",
              "      <td>0.692841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>0.991400</td>\n",
              "      <td>1.113125</td>\n",
              "      <td>0.694383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 91\u001b[0m\n\u001b[1;32m     82\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     83\u001b[0m     model\u001b[39m=\u001b[39mmodel,                         \u001b[39m# 학습시킬 모델\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,                  \u001b[39m# 학습 인자\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics      \u001b[39m# 평가 메트릭 계산 함수\u001b[39;00m\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[39m# 모델 학습\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:1664\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1661\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1662\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1663\u001b[0m )\n\u001b[0;32m-> 1664\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1665\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1666\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1667\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1668\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1669\u001b[0m )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:1942\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1939\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1940\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m-> 1942\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1943\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1944\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1945\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1946\u001b[0m ):\n\u001b[1;32m   1947\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1949\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# 정확도를 계산하는 함수\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)}\n",
        "\n",
        "# 데이터 로드 및 토큰화\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-large')\n",
        "\n",
        "# 만약 x_train과 x_valid가 pandas Series 객체라면, 이를 list로 변환\n",
        "x_train = x_train_1.tolist()\n",
        "x_valid = x_valid_1.tolist()\n",
        "\n",
        "print(y_train_1)\n",
        "\n",
        "# y_train과 y_valid가 텍스트 라벨이라면, 이를 정수형 라벨로 변환\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train_1)\n",
        "y_valid = le.transform(y_valid_1)\n",
        "\n",
        "print(y_train)\n",
        "\n",
        "import pickle\n",
        "\n",
        "# LabelEncoder 객체를 저장합니다.\n",
        "with open('label_encoder_large.pkl', 'wb') as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "# 나중에 LabelEncoder 객체를 로드합니다.\n",
        "with open('label_encoder_large.pkl', 'rb') as f:\n",
        "    loaded_le = pickle.load(f)\n",
        "\n",
        "\n",
        "train_encodings = tokenizer(x_train, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(x_valid, truncation=True, padding=True)\n",
        "\n",
        "# 데이터셋 생성\n",
        "train_dataset = CustomDataset(train_encodings, y_train)\n",
        "valid_dataset = CustomDataset(valid_encodings, y_valid)\n",
        "\n",
        "# 모델 생성\n",
        "num_labels = len(set(y_train))  # 클래스 수를 정의합니다.\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-large', num_labels=num_labels)\n",
        "\n",
        "# 학습 및 검증 인자 정의\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results/roberta-large',          # 출력 결과를 저장할 경로\n",
        "    save_strategy = \"epoch\",\n",
        "    save_total_limit = 3,\n",
        "    num_train_epochs=3,              # 훈련 에포크 수\n",
        "    per_device_train_batch_size=8,  # 훈련 배치 크기\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate = 1e-05,# 검증 배치 크기\n",
        "    warmup_steps=500,                # 워밍업 스텝 수\n",
        "    weight_decay=0.01,               # 가중치 감쇠 비율\n",
        "    logging_dir='./logs',            # 로그를 저장할 경로\n",
        "    logging_steps=1000,                # 로깅할 스텝 크기\n",
        "    evaluation_strategy='steps',     # 스텝마다 evaluation을 수행합니다.\n",
        "    eval_steps=1000,                  # 500스텝마다 evaluation을 수행합니다.\n",
        ")\n",
        "\n",
        "# Trainer 생성 및 학습\n",
        "trainer = Trainer(\n",
        "    model=model,                         # 학습시킬 모델\n",
        "    args=training_args,                  # 학습 인자\n",
        "    train_dataset=train_dataset,         # 훈련 데이터셋\n",
        "    eval_dataset=valid_dataset,          # 검증 데이터셋\n",
        "    compute_metrics=compute_metrics      # 평가 메트릭 계산 함수\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_genre(text, model, tokenizer, label_encoder):\n",
        "    # 텍스트를 토큰화합니다\n",
        "    inputs = tokenizer([text], return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "    # GPU를 사용할 수 있으면 GPU로 이동합니다\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {name: tensor.to('cuda') for name, tensor in inputs.items()}\n",
        "\n",
        "    # 예측을 수행합니다\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # 가장 높은 확률을 가진 클래스를 찾습니다\n",
        "    predicted_class = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # 클래스를 원래의 텍스트 라벨로 변환합니다\n",
        "    predicted_label = label_encoder.inverse_transform(predicted_class.cpu().numpy())\n",
        "    print(predicted_label)\n",
        "    return predicted_label[0]  # 결과가 리스트인데 첫 번째 요소만 반환합니다.\n",
        "\n",
        "# 예제 텍스트\n",
        "text = \"This is a new text.\"\n",
        "\n",
        "# 텍스트의 장르 예측\n",
        "predicted_genre = predict_genre(text, model, tokenizer, le)  # 'le'를 사용하셔야 합니다.\n",
        "print(predicted_genre)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Expected string label but got integer label. Please check the fit of the label encoder. First few classes: [0 1 2 3 4]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "def predict_genre(text, model, tokenizer, label_encoder):\n",
        "    # 텍스트를 토큰화합니다\n",
        "    inputs = tokenizer([text], return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "    # GPU를 사용할 수 있으면 GPU로 이동합니다\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {name: tensor.to('cuda') for name, tensor in inputs.items()}\n",
        "\n",
        "    # 예측을 수행합니다\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # 가장 높은 확률을 가진 클래스를 찾습니다\n",
        "    predicted_class = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # 클래스를 원래의 텍스트 라벨로 변환합니다\n",
        "    predicted_label = label_encoder.inverse_transform(predicted_class.cpu().numpy())\n",
        "\n",
        "    # 결과가 숫자로 나오는 경우에 대한 디버깅\n",
        "    if isinstance(predicted_label[0], (int, np.integer)):\n",
        "        print(f\"Warning: Expected string label but got integer label. Please check the fit of the label encoder. First few classes: {le.classes_[:5]}\")\n",
        "        \n",
        "    return predicted_label[0]  # 결과가 리스트인데 첫 번째 요소만 반환합니다.\n",
        "\n",
        "# 예제 텍스트\n",
        "text = \"This is a new text.\"\n",
        "\n",
        "# 텍스트의 장르 예측\n",
        "predicted_genre = predict_genre(text, model, tokenizer, le)  # 'le'를 사용하셔야 합니다.\n",
        "print(predicted_genre)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# distilbert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "182399           Children's Books\n",
            "170154         Teen & Young Adult\n",
            "4138      Comics & Graphic Novels\n",
            "47472      Crafts, Hobbies & Home\n",
            "185004           Children's Books\n",
            "                   ...           \n",
            "183203           Children's Books\n",
            "46799      Crafts, Hobbies & Home\n",
            "203282                     Travel\n",
            "157723    Religion & Spirituality\n",
            "48450      Crafts, Hobbies & Home\n",
            "Name: Genre, Length: 186813, dtype: object\n",
            "[ 4 29  6 ... 31 23  9]\n",
            "32\n",
            "32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70056' max='70056' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70056/70056 1:43:39, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.754400</td>\n",
              "      <td>2.001241</td>\n",
              "      <td>0.487089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.840800</td>\n",
              "      <td>1.638929</td>\n",
              "      <td>0.562241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.588100</td>\n",
              "      <td>1.490045</td>\n",
              "      <td>0.595433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.508100</td>\n",
              "      <td>1.405898</td>\n",
              "      <td>0.613932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.434600</td>\n",
              "      <td>1.351962</td>\n",
              "      <td>0.625205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.356600</td>\n",
              "      <td>1.319281</td>\n",
              "      <td>0.632238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.352300</td>\n",
              "      <td>1.294036</td>\n",
              "      <td>0.639850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.310400</td>\n",
              "      <td>1.268365</td>\n",
              "      <td>0.649581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>1.303000</td>\n",
              "      <td>1.252285</td>\n",
              "      <td>0.652616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.279100</td>\n",
              "      <td>1.233964</td>\n",
              "      <td>0.654880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>1.227000</td>\n",
              "      <td>1.219407</td>\n",
              "      <td>0.658445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.230600</td>\n",
              "      <td>1.203338</td>\n",
              "      <td>0.662106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>1.106000</td>\n",
              "      <td>1.202032</td>\n",
              "      <td>0.663021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.121800</td>\n",
              "      <td>1.196345</td>\n",
              "      <td>0.665960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>1.097700</td>\n",
              "      <td>1.186891</td>\n",
              "      <td>0.668465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>1.096900</td>\n",
              "      <td>1.179906</td>\n",
              "      <td>0.671693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>1.087200</td>\n",
              "      <td>1.171433</td>\n",
              "      <td>0.674102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>1.099100</td>\n",
              "      <td>1.166051</td>\n",
              "      <td>0.676847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>1.097600</td>\n",
              "      <td>1.160478</td>\n",
              "      <td>0.676944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>1.097200</td>\n",
              "      <td>1.154043</td>\n",
              "      <td>0.676751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>1.102600</td>\n",
              "      <td>1.143274</td>\n",
              "      <td>0.679642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>1.079200</td>\n",
              "      <td>1.144226</td>\n",
              "      <td>0.679738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>1.064700</td>\n",
              "      <td>1.132529</td>\n",
              "      <td>0.682388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>0.974100</td>\n",
              "      <td>1.138470</td>\n",
              "      <td>0.682966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>0.942700</td>\n",
              "      <td>1.150423</td>\n",
              "      <td>0.680846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>0.937700</td>\n",
              "      <td>1.141896</td>\n",
              "      <td>0.683255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>0.958400</td>\n",
              "      <td>1.145818</td>\n",
              "      <td>0.682050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>0.928700</td>\n",
              "      <td>1.136554</td>\n",
              "      <td>0.685085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>0.949400</td>\n",
              "      <td>1.132230</td>\n",
              "      <td>0.685904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>0.938400</td>\n",
              "      <td>1.137921</td>\n",
              "      <td>0.686627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31000</td>\n",
              "      <td>0.931400</td>\n",
              "      <td>1.141941</td>\n",
              "      <td>0.686001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>0.929200</td>\n",
              "      <td>1.136751</td>\n",
              "      <td>0.686193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33000</td>\n",
              "      <td>0.916500</td>\n",
              "      <td>1.135922</td>\n",
              "      <td>0.684796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>0.939600</td>\n",
              "      <td>1.126402</td>\n",
              "      <td>0.689132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>0.943500</td>\n",
              "      <td>1.121509</td>\n",
              "      <td>0.689806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36000</td>\n",
              "      <td>0.815700</td>\n",
              "      <td>1.138358</td>\n",
              "      <td>0.689469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37000</td>\n",
              "      <td>0.818700</td>\n",
              "      <td>1.139055</td>\n",
              "      <td>0.688843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38000</td>\n",
              "      <td>0.811300</td>\n",
              "      <td>1.139641</td>\n",
              "      <td>0.690240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39000</td>\n",
              "      <td>0.823000</td>\n",
              "      <td>1.147756</td>\n",
              "      <td>0.688650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>0.821600</td>\n",
              "      <td>1.145694</td>\n",
              "      <td>0.687494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41000</td>\n",
              "      <td>0.825200</td>\n",
              "      <td>1.141569</td>\n",
              "      <td>0.689276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42000</td>\n",
              "      <td>0.811300</td>\n",
              "      <td>1.146265</td>\n",
              "      <td>0.689517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43000</td>\n",
              "      <td>0.819500</td>\n",
              "      <td>1.144275</td>\n",
              "      <td>0.691926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44000</td>\n",
              "      <td>0.816900</td>\n",
              "      <td>1.138916</td>\n",
              "      <td>0.689855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45000</td>\n",
              "      <td>0.805500</td>\n",
              "      <td>1.133777</td>\n",
              "      <td>0.692889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46000</td>\n",
              "      <td>0.818800</td>\n",
              "      <td>1.135318</td>\n",
              "      <td>0.693468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47000</td>\n",
              "      <td>0.798900</td>\n",
              "      <td>1.140212</td>\n",
              "      <td>0.691300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48000</td>\n",
              "      <td>0.750200</td>\n",
              "      <td>1.146709</td>\n",
              "      <td>0.691685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49000</td>\n",
              "      <td>0.733800</td>\n",
              "      <td>1.153515</td>\n",
              "      <td>0.692167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50000</td>\n",
              "      <td>0.738400</td>\n",
              "      <td>1.155440</td>\n",
              "      <td>0.692504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51000</td>\n",
              "      <td>0.739000</td>\n",
              "      <td>1.156481</td>\n",
              "      <td>0.690433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52000</td>\n",
              "      <td>0.737200</td>\n",
              "      <td>1.155490</td>\n",
              "      <td>0.692504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53000</td>\n",
              "      <td>0.742400</td>\n",
              "      <td>1.149729</td>\n",
              "      <td>0.691781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54000</td>\n",
              "      <td>0.738500</td>\n",
              "      <td>1.154814</td>\n",
              "      <td>0.692504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55000</td>\n",
              "      <td>0.729100</td>\n",
              "      <td>1.155970</td>\n",
              "      <td>0.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56000</td>\n",
              "      <td>0.732600</td>\n",
              "      <td>1.152539</td>\n",
              "      <td>0.692649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57000</td>\n",
              "      <td>0.727800</td>\n",
              "      <td>1.154997</td>\n",
              "      <td>0.693227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58000</td>\n",
              "      <td>0.723700</td>\n",
              "      <td>1.152976</td>\n",
              "      <td>0.693997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59000</td>\n",
              "      <td>0.691700</td>\n",
              "      <td>1.157703</td>\n",
              "      <td>0.693660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60000</td>\n",
              "      <td>0.677400</td>\n",
              "      <td>1.163644</td>\n",
              "      <td>0.693371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61000</td>\n",
              "      <td>0.686500</td>\n",
              "      <td>1.164534</td>\n",
              "      <td>0.692793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62000</td>\n",
              "      <td>0.687100</td>\n",
              "      <td>1.163355</td>\n",
              "      <td>0.693757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63000</td>\n",
              "      <td>0.674000</td>\n",
              "      <td>1.164953</td>\n",
              "      <td>0.694094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64000</td>\n",
              "      <td>0.678600</td>\n",
              "      <td>1.165554</td>\n",
              "      <td>0.693323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65000</td>\n",
              "      <td>0.663200</td>\n",
              "      <td>1.165835</td>\n",
              "      <td>0.693901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66000</td>\n",
              "      <td>0.675900</td>\n",
              "      <td>1.166375</td>\n",
              "      <td>0.693227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67000</td>\n",
              "      <td>0.691400</td>\n",
              "      <td>1.165467</td>\n",
              "      <td>0.693949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68000</td>\n",
              "      <td>0.674500</td>\n",
              "      <td>1.165673</td>\n",
              "      <td>0.694238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69000</td>\n",
              "      <td>0.655700</td>\n",
              "      <td>1.166571</td>\n",
              "      <td>0.695009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70000</td>\n",
              "      <td>0.697400</td>\n",
              "      <td>1.166066</td>\n",
              "      <td>0.695298</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=70056, training_loss=0.9648476638545643, metrics={'train_runtime': 6219.6244, 'train_samples_per_second': 180.216, 'train_steps_per_second': 11.264, 'total_flos': 3.772011715984512e+16, 'train_loss': 0.9648476638545643, 'epoch': 6.0})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# 정확도를 계산하는 함수\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)}\n",
        "\n",
        "# 데이터 로드 및 토큰화\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# 만약 x_train과 x_valid가 pandas Series 객체라면, 이를 list로 변환\n",
        "x_train = x_train_1.tolist()\n",
        "x_valid = x_valid_1.tolist()\n",
        "\n",
        "print(y_train_1)\n",
        "\n",
        "# y_train과 y_valid가 텍스트 라벨이라면, 이를 정수형 라벨로 변환\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train_1)\n",
        "y_valid = le.transform(y_valid_1)\n",
        "\n",
        "print(y_train)\n",
        "\n",
        "import pickle\n",
        "\n",
        "# LabelEncoder 객체를 저장합니다.\n",
        "with open('label_encoder_distil_2.pkl', 'wb') as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "# 나중에 LabelEncoder 객체를 로드합니다.\n",
        "with open('label_encoder_distil_2.pkl', 'rb') as f:\n",
        "    loaded_le = pickle.load(f)\n",
        "\n",
        "\n",
        "train_encodings = tokenizer(x_train, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(x_valid, truncation=True, padding=True)\n",
        "\n",
        "# 데이터셋 생성\n",
        "train_dataset = CustomDataset(train_encodings, y_train)\n",
        "valid_dataset = CustomDataset(valid_encodings, y_valid)\n",
        "\n",
        "# 모델 생성\n",
        "num_labels = len(set(y_train))  # 클래스 수를 정의합니다.\n",
        "\n",
        "print(len(set(y_train)))\n",
        "print(len(set(y_valid)))\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=32)\n",
        "\n",
        "\n",
        "# 학습 및 검증 인자 정의\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results/distil/2',          # 출력 결과를 저장할 경로\n",
        "    save_strategy = \"epoch\",\n",
        "    save_total_limit = 3,\n",
        "    num_train_epochs=6,              # 훈련 에포크 수\n",
        "    per_device_train_batch_size=16,  # 훈련 배치 크기\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate = 1e-05,# 검증 배치 크기\n",
        "    warmup_steps=500,                # 워밍업 스텝 수\n",
        "    weight_decay=0.01,               # 가중치 감쇠 비율\n",
        "    logging_dir='./logs',            # 로그를 저장할 경로\n",
        "    logging_steps=1000,                # 로깅할 스텝 크기\n",
        "    evaluation_strategy='steps',     # 스텝마다 evaluation을 수행합니다.\n",
        "    eval_steps=1000,                  # 500스텝마다 evaluation을 수행합니다.\n",
        ")\n",
        "\n",
        "# Trainer 생성 및 학습\n",
        "trainer = Trainer(\n",
        "    model=model,                         # 학습시킬 모델\n",
        "    args=training_args,                  # 학습 인자\n",
        "    train_dataset=train_dataset,         # 훈련 데이터셋\n",
        "    eval_dataset=valid_dataset,          # 검증 데이터셋\n",
        "    compute_metrics=compute_metrics      # 평가 메트릭 계산 함수\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 저장\n",
        "trainer.save_model(\"./model/distil_0.694\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('label_encoder_large.pkl', 'rb') as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('./results/roberta-large/checkpoint-70056', num_labels=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Biographies & Memoirs' 'Literature & Fiction' 'Teen & Young Adult']\n",
            "['Biographies & Memoirs' 'Literature & Fiction' 'Teen & Young Adult']\n"
          ]
        }
      ],
      "source": [
        "def predict_genre(text, model, tokenizer, label_encoder, k=3):\n",
        "    # 디바이스 설정\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    \n",
        "    # 모델을 올바른 디바이스로 이동\n",
        "    model.to(device)\n",
        "\n",
        "    # 텍스트를 토큰화합니다\n",
        "    inputs = tokenizer([text], return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "\n",
        "    # 예측을 수행합니다\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # 가장 높은 확률을 가진 클래스를 찾습니다\n",
        "    topk_values, topk_indices = torch.topk(outputs.logits, k, dim=-1)\n",
        "\n",
        "    # 클래스를 원래의 텍스트 라벨로 변환합니다\n",
        "    predicted_labels = label_encoder.inverse_transform(topk_indices.cpu().numpy()[0])\n",
        "    print(predicted_labels)\n",
        "    return predicted_labels  # 결과가 리스트인데 첫 번째 요소만 반환합니다.\n",
        "\n",
        "# 예제 텍스트\n",
        "text = \"He died yesterday\"\n",
        "\n",
        "# 텍스트의 장르 예측\n",
        "predicted_genres = predict_genre(text, model, tokenizer, le, k=3)  # 'le'를 사용하셔야 합니다.\n",
        "print(predicted_genres)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 나머지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15 15]\n"
          ]
        }
      ],
      "source": [
        "# 예제 텍스트\n",
        "texts = [\"This is a new text.\", \"Here's another one.\"]\n",
        "\n",
        "# 텍스트의 장르 예측\n",
        "predicted_genres = predict_genre(texts, model, tokenizer)\n",
        "print(predicted_genres)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_dict = {}\n",
        "for index, genre in enumerate(list(df['Genre'].unique())):\n",
        "    encoded_dict[genre] = int(index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.concat([x_train, y_train], axis = 1)\n",
        "df_test = pd.concat([x_train, y_train], axis = 1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130368</th>\n",
              "      <td>Calvin Coolidge</td>\n",
              "      <td>Biographies &amp; Memoirs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146910</th>\n",
              "      <td>The Good Shepherd: A Thousand-Year Journey fro...</td>\n",
              "      <td>Christian Books &amp; Bibles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173744</th>\n",
              "      <td>Daoism (World Religions (Facts on File))</td>\n",
              "      <td>Teen &amp; Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188047</th>\n",
              "      <td>QB 1</td>\n",
              "      <td>Children's Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93154</th>\n",
              "      <td>Storm Surge: Hurricane Sandy, Our Changing Cli...</td>\n",
              "      <td>Science &amp; Math</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99805</th>\n",
              "      <td>The Husband's Field Guide: Navigating Your Wif...</td>\n",
              "      <td>Health, Fitness &amp; Dieting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186882</th>\n",
              "      <td>Tickle Monster</td>\n",
              "      <td>Children's Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62700</th>\n",
              "      <td>How to Find Scholarships and Free Financial Ai...</td>\n",
              "      <td>Education &amp; Teaching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67598</th>\n",
              "      <td>The Secrets of Making Love Happen: How to Find...</td>\n",
              "      <td>Self-Help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106437</th>\n",
              "      <td>Baby Bod: Turn Flab to Fab in 12 Weeks Flat!</td>\n",
              "      <td>Health, Fitness &amp; Dieting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>166056 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Title  \\\n",
              "130368                                    Calvin Coolidge   \n",
              "146910  The Good Shepherd: A Thousand-Year Journey fro...   \n",
              "173744           Daoism (World Religions (Facts on File))   \n",
              "188047                                               QB 1   \n",
              "93154   Storm Surge: Hurricane Sandy, Our Changing Cli...   \n",
              "...                                                   ...   \n",
              "99805   The Husband's Field Guide: Navigating Your Wif...   \n",
              "186882                                     Tickle Monster   \n",
              "62700   How to Find Scholarships and Free Financial Ai...   \n",
              "67598   The Secrets of Making Love Happen: How to Find...   \n",
              "106437       Baby Bod: Turn Flab to Fab in 12 Weeks Flat!   \n",
              "\n",
              "                            Genre  \n",
              "130368      Biographies & Memoirs  \n",
              "146910   Christian Books & Bibles  \n",
              "173744         Teen & Young Adult  \n",
              "188047           Children's Books  \n",
              "93154              Science & Math  \n",
              "...                           ...  \n",
              "99805   Health, Fitness & Dieting  \n",
              "186882           Children's Books  \n",
              "62700        Education & Teaching  \n",
              "67598                   Self-Help  \n",
              "106437  Health, Fitness & Dieting  \n",
              "\n",
              "[166056 rows x 2 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Calendars': 0, 'Comics & Graphic Novels': 1, 'Test Preparation': 2, 'Mystery, Thriller & Suspense': 3, 'Science Fiction & Fantasy': 4, 'Romance': 5, 'Humor & Entertainment': 6, 'Literature & Fiction': 7, 'Gay & Lesbian': 8, 'Engineering & Transportation': 9, 'Cookbooks, Food & Wine': 10, 'Crafts, Hobbies & Home': 11, 'Arts & Photography': 12, 'Education & Teaching': 13, 'Parenting & Relationships': 14, 'Self-Help': 15, 'Computers & Technology': 16, 'Medical Books': 17, 'Science & Math': 18, 'Health, Fitness & Dieting': 19, 'Business & Money': 20, 'Law': 21, 'Biographies & Memoirs': 22, 'History': 23, 'Politics & Social Sciences': 24, 'Reference': 25, 'Christian Books & Bibles': 26, 'Religion & Spirituality': 27, 'Sports & Outdoors': 28, 'Teen & Young Adult': 29, \"Children's Books\": 30, 'Travel': 31}\n"
          ]
        }
      ],
      "source": [
        "print(encoded_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train['Genre'] = df_train.Genre.map(encoded_dict)\n",
        "df_test['Genre'] = df_test.Genre.map(encoded_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(df_train.Genre)\n",
        "y_test = to_categorical(df_test.Genre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading pytorch_model.bin: 100%|██████████| 436M/436M [00:04<00:00, 103MB/s]  \n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, TFAutoModelForSequenceClassification\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = tokenizer(\n",
        "    text=df_train.Title.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=70,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "x_test = tokenizer(\n",
        "    text=df_test.Title.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=70,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = tokenizer(text=df_train.Title.tolist(), return_tensors='pt' ,truncation=True,\n",
        "    padding=True, )\n",
        "x_test = tokenizer(text=df_test.Title.tolist(), return_tensors='pt', truncation=True,\n",
        "    padding=True, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids = x_train['input_ids']\n",
        "attention_mask = x_train['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(166056, 70), dtype=int32, numpy=\n",
              "array([[  101, 11110, 13297, ...,     0,     0,     0],\n",
              "       [  101,  1109,  2750, ...,     0,     0,     0],\n",
              "       [  101, 10136,  8586, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  1731,  1106, ...,     0,     0,     0],\n",
              "       [  101,  1109, 19958, ...,     0,     0,     0],\n",
              "       [  101,  6008,  9326, ...,     0,     0,     0]], dtype=int32)>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "\n",
        "max_len = 70\n",
        "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = model(input_ids,attention_mask = input_mask)[0]\n",
        "# embeddings = bert(input_ids,attention_mask = input_mask)[0]\n",
        "#out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = Dense(128, activation='relu')(embeddings)\n",
        "#out = Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "y = Dense(32,activation = 'sigmoid')(out)\n",
        "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
        "model.layers[2].trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'tf_bert_for_sequence_classification_1')>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "# Set loss and metrics\n",
        "loss =CategoricalCrossentropy(from_logits = True)\n",
        "metric = CategoricalAccuracy('balanced_accuracy'),\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('CUDA : 0')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n",
            "Is TensorFlow built with CUDA:  True\n",
            "Is GPU available:  False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-18 15:01:52.129080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-07-18 15:01:52.130226: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 사용 가능한 GPU의 수를 확인\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# TensorFlow가 현재 GPU를 사용하고 있는지 확인\n",
        "print(\"Is TensorFlow built with CUDA: \", tf.test.is_built_with_cuda())\n",
        "print(\"Is GPU available: \", tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 295/4613 [>.............................] - ETA: 5:14:59 - loss: 3.2835 - balanced_accuracy: 0.0845"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      2\u001b[0m     x \u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m:x_train[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m:x_train[\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m]} ,\n\u001b[1;32m      3\u001b[0m     y \u001b[39m=\u001b[39;49m y_train,\n\u001b[1;32m      4\u001b[0m     validation_data \u001b[39m=\u001b[39;49m (\n\u001b[1;32m      5\u001b[0m     {\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m:x_test[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m:x_test[\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m]}, y_test\n\u001b[1;32m      6\u001b[0m     ),\n\u001b[1;32m      7\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m36\u001b[39;49m\n\u001b[1;32m      9\u001b[0m )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_history = model.fit(\n",
        "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
        "    y = y_train,\n",
        "    validation_data = (\n",
        "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, y_test\n",
        "    ),\n",
        "  epochs=1,\n",
        "    batch_size=36\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_raw = model.predict({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})\n",
        "predicted_raw[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytorch_lightning'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader, Dataset\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningModule, Trainer\n\u001b[1;32m      6\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBertClassifier\u001b[39;00m(LightningModule):\n\u001b[1;32m      7\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, num_classes: \u001b[39mint\u001b[39m):\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "\n",
        "class BertClassifier(LightningModule):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_classes)\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        return outputs\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = self(input_ids, attention_mask, labels)\n",
        "        loss = self.criterion(outputs.logits, labels)\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = self(input_ids, attention_mask, labels)\n",
        "        loss = self.criterion(outputs.logits, labels)\n",
        "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(), lr=1e-5)\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# 데이터 로드 및 BERT tokenizer 로드\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "data = x_train  # 여기에 당신의 데이터를 로드해주세요. \n",
        "labels = y_train  # 여기에 당신의 라벨을 로드해주세요.\n",
        "encodings = tokenizer(data, truncation=True, padding=True)\n",
        "\n",
        "# PyTorch dataset 및 dataloader 생성\n",
        "dataset = TextDataset(encodings, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "\n",
        "val_data = x_valid  # 여기에 당신의 검증 데이터를 로드해주세요. \n",
        "val_labels = y_valid  # 여기에 당신의 검증 라벨을 로드해주세요.\n",
        "val_encodings = tokenizer(val_data, truncation=True, padding=True)\n",
        "\n",
        "# PyTorch dataset 및 dataloader 생성\n",
        "val_dataset = TextDataset(val_encodings, val_labels)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# 모델 초기화 및 훈련\n",
        "num_classes = 32  # 클래스의 수를 정의해주세요\n",
        "model = BertClassifier(num_classes=num_classes)\n",
        "trainer = Trainer(max_epochs=3, gpus=1)  # GPU를 사용하여 3 에포크동안 모델을 훈련\n",
        "trainer.fit(model, dataloader, val_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytorch_lightning'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
          ]
        }
      ],
      "source": [
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyYAML\n",
            "  Using cached PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
            "Installing collected packages: PyYAML\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.0.14.1 requires numpy==1.18.5, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-5.3.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --ignore-installed PyYAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Using cached pytorch_lightning-2.0.5-py3-none-any.whl (722 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (1.24.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (2.0.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (4.65.0)\n",
            "Collecting PyYAML>=5.4 (from pytorch-lightning)\n",
            "  Using cached PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (0.11.4)\n",
            "Requirement already satisfied: packaging>=17.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (4.5.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning)\n",
            "  Using cached lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (3.0.12)\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.8/site-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->pytorch-lightning) (50.3.1.post20201107)\n",
            "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->pytorch-lightning) (0.35.1)\n",
            "Requirement already satisfied: cmake in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.26.4)\n",
            "Requirement already satisfied: lit in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.5.post0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2020.12.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: PyYAML, lightning-utilities, pytorch-lightning\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 5.3.1\n",
            "\u001b[31mERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch-lightning"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "082e886bae1d4e3c9465f20be3d4c447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b32192206341455bbebaf55c5d760d41",
            "max": 51893,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a392e021f32b49498aeca03c7086ab01",
            "value": 51893
          }
        },
        "0dfc9118ee7d42fa92fda279345d10dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22381a54d4854bf9b91359a7a9350376",
              "IPY_MODEL_eaf55fce655d4994a5cd9ff1487eaa56",
              "IPY_MODEL_c8f876bb3e8a4450b7e29cf00156ea37"
            ],
            "layout": "IPY_MODEL_8e17a5a48f53479ca136c6c138475c3b"
          }
        },
        "172c2cbc98394b6a8cb8c95422c135c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f592f8297cb492d987487fed60b7bac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22381a54d4854bf9b91359a7a9350376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f592f8297cb492d987487fed60b7bac",
            "placeholder": "​",
            "style": "IPY_MODEL_febf78deccd44831ac99ae03bb101b28",
            "value": "Map: 100%"
          }
        },
        "2bbcaa400d30438886f13c9a0bb0a952": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "44216e22badc4bb2bff956981fb96822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0e5d8adfa1a400a81068b1b6b0592f7",
            "placeholder": "​",
            "style": "IPY_MODEL_c715271327374383b715b8bae194bf73",
            "value": " 51893/51893 [00:18&lt;00:00, 3681.12 examples/s]"
          }
        },
        "6e3e6be2f7d34a04a777ee11f0193ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72db8ce1a8e145d4b304579700e3a5af",
            "placeholder": "​",
            "style": "IPY_MODEL_172c2cbc98394b6a8cb8c95422c135c3",
            "value": "Map: 100%"
          }
        },
        "6fd7f606fd5042518f2142b3f469d1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70e0015724664798b85a9160c134d3c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72db8ce1a8e145d4b304579700e3a5af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e17a5a48f53479ca136c6c138475c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a392e021f32b49498aeca03c7086ab01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a86e1d0dd148442da26f04b02a69956c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e3e6be2f7d34a04a777ee11f0193ae2",
              "IPY_MODEL_082e886bae1d4e3c9465f20be3d4c447",
              "IPY_MODEL_44216e22badc4bb2bff956981fb96822"
            ],
            "layout": "IPY_MODEL_2bbcaa400d30438886f13c9a0bb0a952"
          }
        },
        "a99cfadba4584518b70ede37056ab334": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32192206341455bbebaf55c5d760d41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56860f34bc44924a64a1867f01fa074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c715271327374383b715b8bae194bf73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8f876bb3e8a4450b7e29cf00156ea37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e0015724664798b85a9160c134d3c8",
            "placeholder": "​",
            "style": "IPY_MODEL_b56860f34bc44924a64a1867f01fa074",
            "value": " 155678/155678 [00:58&lt;00:00, 3559.46 examples/s]"
          }
        },
        "eaf55fce655d4994a5cd9ff1487eaa56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a99cfadba4584518b70ede37056ab334",
            "max": 155678,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fd7f606fd5042518f2142b3f469d1f3",
            "value": 155678
          }
        },
        "f0e5d8adfa1a400a81068b1b6b0592f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "febf78deccd44831ac99ae03bb101b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
